{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b6c9ae6-5565-4701-a275-cb84647e3939",
   "metadata": {},
   "source": [
    "# Machine Learning Language Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f962bd8-4f17-48ed-a938-9eb93dca306f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\alok3\\anaconda3\\lib\\site-packages (2.18.0)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.19.0-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from tensorflow) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: optree in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\alok3\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Using cached tensorflow-2.19.0-cp312-cp312-win_amd64.whl (376.0 MB)\n",
      "Installing collected packages: tensorflow\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.18.0\n",
      "    Uninstalling tensorflow-2.18.0:\n",
      "      Successfully uninstalled tensorflow-2.18.0\n",
      "  Rolling back uninstall of tensorflow\n",
      "  Moving to c:\\users\\alok3\\anaconda3\\lib\\site-packages\\tensorflow-2.18.0.dist-info\\\n",
      "   from C:\\Users\\alok3\\anaconda3\\Lib\\site-packages\\~ensorflow-2.18.0.dist-info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\alok3\\\\anaconda3\\\\Lib\\\\site-packages\\\\tensorflow\\\\compiler\\\\mlir\\\\lite\\\\python\\\\_pywrap_converter_api.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d756ffb9-2b13-4e11-8b50-b8f16421d77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83b65ef2-1556-44bf-82ca-bd2b0e48e4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = 64         # Batch size for training\n",
    "epochs = 100            # Number of epochs to train for\n",
    "latent_dim = 256        # Latent dimensionality of the encoding space\n",
    "num_samples = 10000     # Number of samples to train on\n",
    "data_path = 'fra.txt'  # Path to the English-French translation data file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8dd4b7b-652c-4848-853f-4c8e32fad330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fra.txt'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c718f01-5ecd-4a18-a3c4-99034e445f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Initialize lists and sets\n",
    "input_texts = []            # List to store English sentences\n",
    "target_texts = []           # List to store French sentences (with start/end tokens)\n",
    "input_characters = set()    # Set to hold unique characters in English\n",
    "target_characters = set()   # Set to hold unique characters in French\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "678b932e-e2e5-4f28-b7a4-58139879a566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and process the data file\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "# Process each line up to the specified number of samples\n",
    "for line in lines[:min(num_samples, len(lines) - 1)]:\n",
    "    # Split each line into input and target text\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "    \n",
    "    # Add start and end sequence tokens to target text\n",
    "    # '\\t' as start sequence, '\\n' as end sequence\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    \n",
    "    # Store the texts\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    \n",
    "    # Collect unique characters from input text\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    \n",
    "    # Collect unique characters from target text\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e179b283-a9d3-4753-9ad4-11ff0b8209f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert character sets to sorted lists\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7613b7b1-82ee-489c-9efd-f138831ef60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 10000\n",
      "Number of unique input tokens: 70\n",
      "Number of unique output tokens: 91\n",
      "Max sequence length for inputs: 14\n",
      "Max sequence length for outputs: 59\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80c24b3b-61ad-4252-933c-d00d9c5cc2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a70ab6e-0d33-4fb7-bf9e-0230e704cda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '!': 1,\n",
       " '\"': 2,\n",
       " '$': 3,\n",
       " '%': 4,\n",
       " '&': 5,\n",
       " \"'\": 6,\n",
       " ',': 7,\n",
       " '-': 8,\n",
       " '.': 9,\n",
       " '0': 10,\n",
       " '1': 11,\n",
       " '2': 12,\n",
       " '3': 13,\n",
       " '5': 14,\n",
       " '7': 15,\n",
       " '8': 16,\n",
       " '9': 17,\n",
       " ':': 18,\n",
       " '?': 19,\n",
       " 'A': 20,\n",
       " 'B': 21,\n",
       " 'C': 22,\n",
       " 'D': 23,\n",
       " 'E': 24,\n",
       " 'F': 25,\n",
       " 'G': 26,\n",
       " 'H': 27,\n",
       " 'I': 28,\n",
       " 'J': 29,\n",
       " 'K': 30,\n",
       " 'L': 31,\n",
       " 'M': 32,\n",
       " 'N': 33,\n",
       " 'O': 34,\n",
       " 'P': 35,\n",
       " 'Q': 36,\n",
       " 'R': 37,\n",
       " 'S': 38,\n",
       " 'T': 39,\n",
       " 'U': 40,\n",
       " 'V': 41,\n",
       " 'W': 42,\n",
       " 'Y': 43,\n",
       " 'a': 44,\n",
       " 'b': 45,\n",
       " 'c': 46,\n",
       " 'd': 47,\n",
       " 'e': 48,\n",
       " 'f': 49,\n",
       " 'g': 50,\n",
       " 'h': 51,\n",
       " 'i': 52,\n",
       " 'j': 53,\n",
       " 'k': 54,\n",
       " 'l': 55,\n",
       " 'm': 56,\n",
       " 'n': 57,\n",
       " 'o': 58,\n",
       " 'p': 59,\n",
       " 'q': 60,\n",
       " 'r': 61,\n",
       " 's': 62,\n",
       " 't': 63,\n",
       " 'u': 64,\n",
       " 'v': 65,\n",
       " 'w': 66,\n",
       " 'x': 67,\n",
       " 'y': 68,\n",
       " 'z': 69}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "564436e3-68c9-4f3d-a743-4bfebf12483a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t': 0,\n",
       " '\\n': 1,\n",
       " ' ': 2,\n",
       " '!': 3,\n",
       " '%': 4,\n",
       " '&': 5,\n",
       " \"'\": 6,\n",
       " ',': 7,\n",
       " '-': 8,\n",
       " '.': 9,\n",
       " '0': 10,\n",
       " '1': 11,\n",
       " '2': 12,\n",
       " '3': 13,\n",
       " '5': 14,\n",
       " '8': 15,\n",
       " '9': 16,\n",
       " ':': 17,\n",
       " '?': 18,\n",
       " 'A': 19,\n",
       " 'B': 20,\n",
       " 'C': 21,\n",
       " 'D': 22,\n",
       " 'E': 23,\n",
       " 'F': 24,\n",
       " 'G': 25,\n",
       " 'H': 26,\n",
       " 'I': 27,\n",
       " 'J': 28,\n",
       " 'K': 29,\n",
       " 'L': 30,\n",
       " 'M': 31,\n",
       " 'N': 32,\n",
       " 'O': 33,\n",
       " 'P': 34,\n",
       " 'Q': 35,\n",
       " 'R': 36,\n",
       " 'S': 37,\n",
       " 'T': 38,\n",
       " 'U': 39,\n",
       " 'V': 40,\n",
       " 'W': 41,\n",
       " 'Y': 42,\n",
       " 'a': 43,\n",
       " 'b': 44,\n",
       " 'c': 45,\n",
       " 'd': 46,\n",
       " 'e': 47,\n",
       " 'f': 48,\n",
       " 'g': 49,\n",
       " 'h': 50,\n",
       " 'i': 51,\n",
       " 'j': 52,\n",
       " 'k': 53,\n",
       " 'l': 54,\n",
       " 'm': 55,\n",
       " 'n': 56,\n",
       " 'o': 57,\n",
       " 'p': 58,\n",
       " 'q': 59,\n",
       " 'r': 60,\n",
       " 's': 61,\n",
       " 't': 62,\n",
       " 'u': 63,\n",
       " 'v': 64,\n",
       " 'w': 65,\n",
       " 'x': 66,\n",
       " 'y': 67,\n",
       " 'z': 68,\n",
       " '\\xa0': 69,\n",
       " '«': 70,\n",
       " '»': 71,\n",
       " 'À': 72,\n",
       " 'Ç': 73,\n",
       " 'É': 74,\n",
       " 'Ê': 75,\n",
       " 'à': 76,\n",
       " 'â': 77,\n",
       " 'ç': 78,\n",
       " 'è': 79,\n",
       " 'é': 80,\n",
       " 'ê': 81,\n",
       " 'î': 82,\n",
       " 'ï': 83,\n",
       " 'ô': 84,\n",
       " 'ù': 85,\n",
       " 'û': 86,\n",
       " 'œ': 87,\n",
       " '\\u2009': 88,\n",
       " '’': 89,\n",
       " '\\u202f': 90}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f8a110c-3e2e-448a-b8bc-425b86a046f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({' ': 0,\n",
       "  '!': 1,\n",
       "  '\"': 2,\n",
       "  '$': 3,\n",
       "  '%': 4,\n",
       "  '&': 5,\n",
       "  \"'\": 6,\n",
       "  ',': 7,\n",
       "  '-': 8,\n",
       "  '.': 9,\n",
       "  '0': 10,\n",
       "  '1': 11,\n",
       "  '2': 12,\n",
       "  '3': 13,\n",
       "  '5': 14,\n",
       "  '7': 15,\n",
       "  '8': 16,\n",
       "  '9': 17,\n",
       "  ':': 18,\n",
       "  '?': 19,\n",
       "  'A': 20,\n",
       "  'B': 21,\n",
       "  'C': 22,\n",
       "  'D': 23,\n",
       "  'E': 24,\n",
       "  'F': 25,\n",
       "  'G': 26,\n",
       "  'H': 27,\n",
       "  'I': 28,\n",
       "  'J': 29,\n",
       "  'K': 30,\n",
       "  'L': 31,\n",
       "  'M': 32,\n",
       "  'N': 33,\n",
       "  'O': 34,\n",
       "  'P': 35,\n",
       "  'Q': 36,\n",
       "  'R': 37,\n",
       "  'S': 38,\n",
       "  'T': 39,\n",
       "  'U': 40,\n",
       "  'V': 41,\n",
       "  'W': 42,\n",
       "  'Y': 43,\n",
       "  'a': 44,\n",
       "  'b': 45,\n",
       "  'c': 46,\n",
       "  'd': 47,\n",
       "  'e': 48,\n",
       "  'f': 49,\n",
       "  'g': 50,\n",
       "  'h': 51,\n",
       "  'i': 52,\n",
       "  'j': 53,\n",
       "  'k': 54,\n",
       "  'l': 55,\n",
       "  'm': 56,\n",
       "  'n': 57,\n",
       "  'o': 58,\n",
       "  'p': 59,\n",
       "  'q': 60,\n",
       "  'r': 61,\n",
       "  's': 62,\n",
       "  't': 63,\n",
       "  'u': 64,\n",
       "  'v': 65,\n",
       "  'w': 66,\n",
       "  'x': 67,\n",
       "  'y': 68,\n",
       "  'z': 69},\n",
       " {'\\t': 0,\n",
       "  '\\n': 1,\n",
       "  ' ': 2,\n",
       "  '!': 3,\n",
       "  '%': 4,\n",
       "  '&': 5,\n",
       "  \"'\": 6,\n",
       "  ',': 7,\n",
       "  '-': 8,\n",
       "  '.': 9,\n",
       "  '0': 10,\n",
       "  '1': 11,\n",
       "  '2': 12,\n",
       "  '3': 13,\n",
       "  '5': 14,\n",
       "  '8': 15,\n",
       "  '9': 16,\n",
       "  ':': 17,\n",
       "  '?': 18,\n",
       "  'A': 19,\n",
       "  'B': 20,\n",
       "  'C': 21,\n",
       "  'D': 22,\n",
       "  'E': 23,\n",
       "  'F': 24,\n",
       "  'G': 25,\n",
       "  'H': 26,\n",
       "  'I': 27,\n",
       "  'J': 28,\n",
       "  'K': 29,\n",
       "  'L': 30,\n",
       "  'M': 31,\n",
       "  'N': 32,\n",
       "  'O': 33,\n",
       "  'P': 34,\n",
       "  'Q': 35,\n",
       "  'R': 36,\n",
       "  'S': 37,\n",
       "  'T': 38,\n",
       "  'U': 39,\n",
       "  'V': 40,\n",
       "  'W': 41,\n",
       "  'Y': 42,\n",
       "  'a': 43,\n",
       "  'b': 44,\n",
       "  'c': 45,\n",
       "  'd': 46,\n",
       "  'e': 47,\n",
       "  'f': 48,\n",
       "  'g': 49,\n",
       "  'h': 50,\n",
       "  'i': 51,\n",
       "  'j': 52,\n",
       "  'k': 53,\n",
       "  'l': 54,\n",
       "  'm': 55,\n",
       "  'n': 56,\n",
       "  'o': 57,\n",
       "  'p': 58,\n",
       "  'q': 59,\n",
       "  'r': 60,\n",
       "  's': 61,\n",
       "  't': 62,\n",
       "  'u': 63,\n",
       "  'v': 64,\n",
       "  'w': 65,\n",
       "  'x': 66,\n",
       "  'y': 67,\n",
       "  'z': 68,\n",
       "  '\\xa0': 69,\n",
       "  '«': 70,\n",
       "  '»': 71,\n",
       "  'À': 72,\n",
       "  'Ç': 73,\n",
       "  'É': 74,\n",
       "  'Ê': 75,\n",
       "  'à': 76,\n",
       "  'â': 77,\n",
       "  'ç': 78,\n",
       "  'è': 79,\n",
       "  'é': 80,\n",
       "  'ê': 81,\n",
       "  'î': 82,\n",
       "  'ï': 83,\n",
       "  'ô': 84,\n",
       "  'ù': 85,\n",
       "  'û': 86,\n",
       "  'œ': 87,\n",
       "  '\\u2009': 88,\n",
       "  '’': 89,\n",
       "  '\\u202f': 90})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_token_index,target_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13fd8dfd-a65b-4116-b85f-47534d430dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86ad61ec-2ae7-40b8-99dd-a790ebe8fd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the input and target texts\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    # Vectorize encoder input (one-hot encoding)\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    # Pad remaining timesteps with space character\n",
    "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    \n",
    "    # Vectorize decoder input and target\n",
    "    for t, char in enumerate(target_text):\n",
    "        # Decoder input (one-hot encoding)\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        \n",
    "        # Decoder target (shifted by one timestep)\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "        \n",
    "        # Pad remaining timesteps with space character\n",
    "        decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "        decoder_target_data[i, t:, target_token_index[' ']] = 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0061093-fc1f-4834-a251-9a507a72c231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder input shape for first sample: (14, 70)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Encoder input shape for first sample:\", encoder_input_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4684df60-d1a8-408d-b5c6-3007cc636fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard encoder_outputs and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2d3338c-b57b-4836-b03f-b979e06c3118",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Set up the decoder, using encoder_states as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                        initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "006fc1e0-2022-4461-a511-71d5a6fa83f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alok3\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_9', 'keras_tensor_13']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 263ms/step - accuracy: 0.9408 - loss: 2.3161 - val_accuracy: 0.9831 - val_loss: 2.2693\n",
      "Epoch 2/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 259ms/step - accuracy: 0.9831 - loss: 2.1282 - val_accuracy: 0.9831 - val_loss: 2.4405\n",
      "Epoch 3/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 257ms/step - accuracy: 0.9831 - loss: 2.3243 - val_accuracy: 0.9831 - val_loss: 2.6207\n",
      "Epoch 4/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 256ms/step - accuracy: 0.9831 - loss: 2.5287 - val_accuracy: 0.9831 - val_loss: 2.8087\n",
      "Epoch 5/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 256ms/step - accuracy: 0.9831 - loss: 2.7352 - val_accuracy: 0.9831 - val_loss: 3.0041\n",
      "Epoch 6/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 257ms/step - accuracy: 0.9831 - loss: 2.9283 - val_accuracy: 0.9831 - val_loss: 3.2041\n",
      "Epoch 7/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 258ms/step - accuracy: 0.9831 - loss: 3.1575 - val_accuracy: 0.9831 - val_loss: 3.3992\n",
      "Epoch 8/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 253ms/step - accuracy: 0.9831 - loss: 3.4120 - val_accuracy: 0.9831 - val_loss: 3.5999\n",
      "Epoch 9/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 260ms/step - accuracy: 0.9831 - loss: 3.5807 - val_accuracy: 0.9831 - val_loss: 3.8292\n",
      "Epoch 10/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 253ms/step - accuracy: 0.9831 - loss: 3.8236 - val_accuracy: 0.9831 - val_loss: 4.0255\n",
      "Epoch 11/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 251ms/step - accuracy: 0.9831 - loss: 4.0249 - val_accuracy: 0.9831 - val_loss: 4.2192\n",
      "Epoch 12/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 248ms/step - accuracy: 0.9831 - loss: 4.2996 - val_accuracy: 0.9831 - val_loss: 4.4274\n",
      "Epoch 13/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 244ms/step - accuracy: 0.9831 - loss: 4.5046 - val_accuracy: 0.9831 - val_loss: 4.6425\n",
      "Epoch 14/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 249ms/step - accuracy: 0.9831 - loss: 4.7198 - val_accuracy: 0.9831 - val_loss: 4.8825\n",
      "Epoch 15/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 249ms/step - accuracy: 0.9831 - loss: 4.9269 - val_accuracy: 0.9831 - val_loss: 5.0768\n",
      "Epoch 16/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 248ms/step - accuracy: 0.9831 - loss: 5.1614 - val_accuracy: 0.9831 - val_loss: 5.2638\n",
      "Epoch 17/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 248ms/step - accuracy: 0.9831 - loss: 5.3769 - val_accuracy: 0.9831 - val_loss: 5.4935\n",
      "Epoch 18/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 249ms/step - accuracy: 0.9831 - loss: 5.6485 - val_accuracy: 0.9831 - val_loss: 5.7059\n",
      "Epoch 19/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 249ms/step - accuracy: 0.9831 - loss: 5.7960 - val_accuracy: 0.9831 - val_loss: 5.9495\n",
      "Epoch 20/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 248ms/step - accuracy: 0.9831 - loss: 6.1267 - val_accuracy: 0.9831 - val_loss: 6.1334\n",
      "Epoch 21/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 249ms/step - accuracy: 0.9831 - loss: 6.4001 - val_accuracy: 0.9831 - val_loss: 6.3648\n",
      "Epoch 22/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 249ms/step - accuracy: 0.9831 - loss: 6.5188 - val_accuracy: 0.9831 - val_loss: 6.5971\n",
      "Epoch 23/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 250ms/step - accuracy: 0.9831 - loss: 6.8574 - val_accuracy: 0.9831 - val_loss: 6.8122\n",
      "Epoch 24/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 248ms/step - accuracy: 0.9831 - loss: 7.0556 - val_accuracy: 0.9831 - val_loss: 7.0273\n",
      "Epoch 25/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 249ms/step - accuracy: 0.9831 - loss: 7.1976 - val_accuracy: 0.9831 - val_loss: 7.2520\n",
      "Epoch 26/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 249ms/step - accuracy: 0.9831 - loss: 7.4284 - val_accuracy: 0.9831 - val_loss: 7.4848\n",
      "Epoch 27/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 249ms/step - accuracy: 0.9831 - loss: 7.7651 - val_accuracy: 0.9831 - val_loss: 7.7071\n",
      "Epoch 28/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 249ms/step - accuracy: 0.9831 - loss: 7.9521 - val_accuracy: 0.9831 - val_loss: 7.9068\n",
      "Epoch 29/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 248ms/step - accuracy: 0.9831 - loss: 8.1250 - val_accuracy: 0.9831 - val_loss: 8.1453\n",
      "Epoch 30/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 249ms/step - accuracy: 0.9831 - loss: 8.4541 - val_accuracy: 0.9831 - val_loss: 8.3923\n",
      "Epoch 31/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 249ms/step - accuracy: 0.9831 - loss: 8.6782 - val_accuracy: 0.9831 - val_loss: 8.5932\n",
      "Epoch 32/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 247ms/step - accuracy: 0.9831 - loss: 8.8850 - val_accuracy: 0.9831 - val_loss: 8.8239\n",
      "Epoch 33/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 252ms/step - accuracy: 0.9831 - loss: 9.2369 - val_accuracy: 0.9831 - val_loss: 9.0282\n",
      "Epoch 34/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 253ms/step - accuracy: 0.9831 - loss: 9.3607 - val_accuracy: 0.9831 - val_loss: 9.2707\n",
      "Epoch 35/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 252ms/step - accuracy: 0.9831 - loss: 9.6386 - val_accuracy: 0.9831 - val_loss: 9.4880\n",
      "Epoch 36/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 251ms/step - accuracy: 0.9831 - loss: 9.8570 - val_accuracy: 0.9831 - val_loss: 9.7367\n",
      "Epoch 37/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 255ms/step - accuracy: 0.9831 - loss: 10.1207 - val_accuracy: 0.9831 - val_loss: 9.9318\n",
      "Epoch 38/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 250ms/step - accuracy: 0.9831 - loss: 10.4021 - val_accuracy: 0.9831 - val_loss: 10.1564\n",
      "Epoch 39/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 250ms/step - accuracy: 0.9831 - loss: 10.5775 - val_accuracy: 0.9831 - val_loss: 10.3916\n",
      "Epoch 40/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 250ms/step - accuracy: 0.9831 - loss: 10.8594 - val_accuracy: 0.9831 - val_loss: 10.6012\n",
      "Epoch 41/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 251ms/step - accuracy: 0.9831 - loss: 10.9496 - val_accuracy: 0.9831 - val_loss: 10.8117\n",
      "Epoch 42/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 250ms/step - accuracy: 0.9831 - loss: 11.2649 - val_accuracy: 0.9831 - val_loss: 11.0556\n",
      "Epoch 43/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 250ms/step - accuracy: 0.9831 - loss: 11.4799 - val_accuracy: 0.9831 - val_loss: 11.2732\n",
      "Epoch 44/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 250ms/step - accuracy: 0.9831 - loss: 11.7271 - val_accuracy: 0.9831 - val_loss: 11.4992\n",
      "Epoch 45/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 250ms/step - accuracy: 0.9831 - loss: 12.0842 - val_accuracy: 0.9831 - val_loss: 11.7403\n",
      "Epoch 46/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 250ms/step - accuracy: 0.9831 - loss: 12.3042 - val_accuracy: 0.9831 - val_loss: 11.9580\n",
      "Epoch 47/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 251ms/step - accuracy: 0.9831 - loss: 12.5951 - val_accuracy: 0.9831 - val_loss: 12.1832\n",
      "Epoch 48/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 255ms/step - accuracy: 0.9831 - loss: 12.6532 - val_accuracy: 0.9831 - val_loss: 12.4011\n",
      "Epoch 49/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 245ms/step - accuracy: 0.9831 - loss: 12.8913 - val_accuracy: 0.9831 - val_loss: 12.6034\n",
      "Epoch 50/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 252ms/step - accuracy: 0.9831 - loss: 13.0777 - val_accuracy: 0.9831 - val_loss: 12.8648\n",
      "Epoch 51/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 253ms/step - accuracy: 0.9831 - loss: 13.5129 - val_accuracy: 0.9831 - val_loss: 13.0655\n",
      "Epoch 52/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 251ms/step - accuracy: 0.9831 - loss: 13.5699 - val_accuracy: 0.9831 - val_loss: 13.3047\n",
      "Epoch 53/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 242ms/step - accuracy: 0.9831 - loss: 14.0645 - val_accuracy: 0.9831 - val_loss: 13.5334\n",
      "Epoch 54/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 244ms/step - accuracy: 0.9831 - loss: 14.0472 - val_accuracy: 0.9831 - val_loss: 13.7569\n",
      "Epoch 55/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 246ms/step - accuracy: 0.9831 - loss: 14.3122 - val_accuracy: 0.9831 - val_loss: 13.9695\n",
      "Epoch 56/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 252ms/step - accuracy: 0.9831 - loss: 14.3809 - val_accuracy: 0.9831 - val_loss: 14.2244\n",
      "Epoch 57/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 252ms/step - accuracy: 0.9831 - loss: 14.9763 - val_accuracy: 0.9831 - val_loss: 14.4280\n",
      "Epoch 58/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 252ms/step - accuracy: 0.9831 - loss: 14.9262 - val_accuracy: 0.9831 - val_loss: 14.6511\n",
      "Epoch 59/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 249ms/step - accuracy: 0.9831 - loss: 15.2111 - val_accuracy: 0.9831 - val_loss: 14.8718\n",
      "Epoch 60/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 239ms/step - accuracy: 0.9831 - loss: 15.6237 - val_accuracy: 0.9831 - val_loss: 15.1012\n",
      "Epoch 61/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 242ms/step - accuracy: 0.9831 - loss: 15.7965 - val_accuracy: 0.9831 - val_loss: 15.3300\n",
      "Epoch 62/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 241ms/step - accuracy: 0.9831 - loss: 15.9019 - val_accuracy: 0.9831 - val_loss: 15.5343\n",
      "Epoch 63/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 246ms/step - accuracy: 0.9831 - loss: 16.3525 - val_accuracy: 0.9831 - val_loss: 15.7817\n",
      "Epoch 64/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 247ms/step - accuracy: 0.9831 - loss: 16.6199 - val_accuracy: 0.9831 - val_loss: 16.0093\n",
      "Epoch 65/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 240ms/step - accuracy: 0.9831 - loss: 16.8054 - val_accuracy: 0.9831 - val_loss: 16.2350\n",
      "Epoch 66/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 251ms/step - accuracy: 0.9831 - loss: 17.0015 - val_accuracy: 0.9831 - val_loss: 16.4616\n",
      "Epoch 67/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 252ms/step - accuracy: 0.9831 - loss: 17.3859 - val_accuracy: 0.9831 - val_loss: 16.6851\n",
      "Epoch 68/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 250ms/step - accuracy: 0.9831 - loss: 17.5632 - val_accuracy: 0.9831 - val_loss: 16.9119\n",
      "Epoch 69/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 249ms/step - accuracy: 0.9831 - loss: 17.8922 - val_accuracy: 0.9831 - val_loss: 17.1388\n",
      "Epoch 70/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 253ms/step - accuracy: 0.9831 - loss: 17.7675 - val_accuracy: 0.9831 - val_loss: 17.3788\n",
      "Epoch 71/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 252ms/step - accuracy: 0.9831 - loss: 18.3437 - val_accuracy: 0.9831 - val_loss: 17.5984\n",
      "Epoch 72/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 252ms/step - accuracy: 0.9831 - loss: 18.6937 - val_accuracy: 0.9831 - val_loss: 17.8472\n",
      "Epoch 73/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 252ms/step - accuracy: 0.9831 - loss: 18.7613 - val_accuracy: 0.9831 - val_loss: 18.0725\n",
      "Epoch 74/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 252ms/step - accuracy: 0.9831 - loss: 19.0610 - val_accuracy: 0.9831 - val_loss: 18.2820\n",
      "Epoch 75/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 250ms/step - accuracy: 0.9831 - loss: 19.3432 - val_accuracy: 0.9831 - val_loss: 18.5269\n",
      "Epoch 76/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 250ms/step - accuracy: 0.9831 - loss: 19.6429 - val_accuracy: 0.9831 - val_loss: 18.7399\n",
      "Epoch 77/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 250ms/step - accuracy: 0.9831 - loss: 19.7704 - val_accuracy: 0.9831 - val_loss: 18.9764\n",
      "Epoch 78/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 253ms/step - accuracy: 0.9831 - loss: 19.9397 - val_accuracy: 0.9831 - val_loss: 19.1996\n",
      "Epoch 79/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 252ms/step - accuracy: 0.9831 - loss: 20.0864 - val_accuracy: 0.9831 - val_loss: 19.4215\n",
      "Epoch 80/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 251ms/step - accuracy: 0.9831 - loss: 20.6017 - val_accuracy: 0.9831 - val_loss: 19.6514\n",
      "Epoch 81/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 248ms/step - accuracy: 0.9831 - loss: 20.4869 - val_accuracy: 0.9831 - val_loss: 19.8758\n",
      "Epoch 82/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 248ms/step - accuracy: 0.9831 - loss: 20.8102 - val_accuracy: 0.9831 - val_loss: 20.1030\n",
      "Epoch 83/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 249ms/step - accuracy: 0.9831 - loss: 21.2485 - val_accuracy: 0.9831 - val_loss: 20.3365\n",
      "Epoch 84/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 250ms/step - accuracy: 0.9831 - loss: 21.2085 - val_accuracy: 0.9831 - val_loss: 20.5513\n",
      "Epoch 85/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 251ms/step - accuracy: 0.9831 - loss: 21.7280 - val_accuracy: 0.9831 - val_loss: 20.7763\n",
      "Epoch 86/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 251ms/step - accuracy: 0.9831 - loss: 21.6782 - val_accuracy: 0.9831 - val_loss: 21.0011\n",
      "Epoch 87/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 252ms/step - accuracy: 0.9831 - loss: 21.9514 - val_accuracy: 0.9831 - val_loss: 21.2137\n",
      "Epoch 88/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 250ms/step - accuracy: 0.9831 - loss: 22.5663 - val_accuracy: 0.9831 - val_loss: 21.4482\n",
      "Epoch 89/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 251ms/step - accuracy: 0.9831 - loss: 22.6328 - val_accuracy: 0.9831 - val_loss: 21.6771\n",
      "Epoch 90/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 249ms/step - accuracy: 0.9831 - loss: 22.5878 - val_accuracy: 0.9831 - val_loss: 21.9182\n",
      "Epoch 91/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 249ms/step - accuracy: 0.9831 - loss: 22.6043 - val_accuracy: 0.9831 - val_loss: 22.1637\n",
      "Epoch 92/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 251ms/step - accuracy: 0.9831 - loss: 23.1446 - val_accuracy: 0.9831 - val_loss: 22.3792\n",
      "Epoch 93/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 251ms/step - accuracy: 0.9831 - loss: 23.7588 - val_accuracy: 0.9831 - val_loss: 22.6090\n",
      "Epoch 94/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 252ms/step - accuracy: 0.9831 - loss: 23.7256 - val_accuracy: 0.9831 - val_loss: 22.8214\n",
      "Epoch 95/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 252ms/step - accuracy: 0.9831 - loss: 24.2077 - val_accuracy: 0.9831 - val_loss: 23.0492\n",
      "Epoch 96/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 251ms/step - accuracy: 0.9831 - loss: 24.2035 - val_accuracy: 0.9831 - val_loss: 23.2853\n",
      "Epoch 97/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 251ms/step - accuracy: 0.9831 - loss: 24.6554 - val_accuracy: 0.9831 - val_loss: 23.5089\n",
      "Epoch 98/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 235ms/step - accuracy: 0.9831 - loss: 24.8840 - val_accuracy: 0.9831 - val_loss: 23.7312\n",
      "Epoch 99/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 230ms/step - accuracy: 0.9831 - loss: 24.7120 - val_accuracy: 0.9831 - val_loss: 23.9621\n",
      "Epoch 100/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 233ms/step - accuracy: 0.9831 - loss: 25.3960 - val_accuracy: 0.9831 - val_loss: 24.2013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22d89827290>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model that will turn\n",
    "# encoder_input_data & decoder_input_data into decoder_target_data\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fd6a41f-d233-4fba-912d-be6a9e708feb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Define sampling models\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m encoder_model \u001b[38;5;241m=\u001b[39m Model(encoder_inputs, encoder_states)\n\u001b[0;32m      4\u001b[0m decoder_state_input_h \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(latent_dim,))\n\u001b[0;32m      5\u001b[0m decoder_state_input_c \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(latent_dim,))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Model' is not defined"
     ]
    }
   ],
   "source": [
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse-Lookup token index to decode sequences back to something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length or find stop character.\n",
    "        if (sampled_char == '\\n' or \n",
    "            len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "# Test the decoder\n",
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set) for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80092926-1860-46fb-b664-e46dea81aba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
